{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX = pd.read_csv('lothlorian_train.data', sep = ' ', header= None)\n",
    "trainY = pd.read_csv('lothlorian_train.solution', sep = ' ', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validX = pd.read_csv('lothlorian_valid.data', sep = ' ', header= None)\n",
    "validY = pd.read_csv('lothlorian_valid.solution', sep = ' ', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = pd.read_csv('lothlorian_test.data', sep = ' ', header= None)\n",
    "testY = pd.read_csv('lothlorian_test.solution', sep = ' ', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "trainXScale = min_max_scaler.fit_transform(trainX)\n",
    "validXScale = min_max_scaler.fit_transform(validX)\n",
    "testXScale = min_max_scaler.fit_transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainXT = trainXScale\n",
    "validXT = validXScale\n",
    "testXT = testXScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "SelectKBestFeature = SelectKBest(chi2, k=50).fit(trainXScale, trainY[0])\n",
    "trainXFeature = SelectKBestFeature.transform(trainXScale)\n",
    "validXFeature = SelectKBestFeature.transform(validXScale)\n",
    "testXFeature = SelectKBestFeature.transform(testXScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainXT = trainXFeature\n",
    "validXT = validXFeature\n",
    "testXT = testXFeature\n",
    "print len(trainX[0]), len(validX[0]) , len(testX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.001,max_depth=1, random_state=0)\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "clf = clf.fit(trainX, trainY[0])\n",
    "\n",
    "trainPreY = clf.predict(trainX)\n",
    "validPreY = clf.predict(validX)\n",
    "testPreY = clf.predict(testX)\n",
    "\n",
    "confusion_matrix1 = confusion_matrix(trainY[0], trainPreY)\n",
    "confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[1,0] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[0,1]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[1,0] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[0,1]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[1,0] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[0,1]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "trainXT = trainX\n",
    "validXT = validX\n",
    "testXT = testX\n",
    "\n",
    "trainAcc = []\n",
    "validAcc = []\n",
    "testAcc = []\n",
    "for i in [500, 1000, 5000, 10000, 15000, 17000]:\n",
    "    \n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(trainXT[0:i], trainY[0][0:i])\n",
    "\n",
    "    trainPreY = clf.predict(trainXT[0:i])\n",
    "    validPreY = clf.predict(validXT)\n",
    "    testPreY = clf.predict(testXT)\n",
    "\n",
    "    confusion_matrix1 = confusion_matrix(trainY[0][0:i], trainPreY[0:i])\n",
    "    confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "    confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[1,0] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[0,1]))                              \n",
    "    print 'Train = ', balance_classification_rate\n",
    "    trainAcc.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[1,0] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[0,1]))                              \n",
    "    print 'Valid = ', balance_classification_rate\n",
    "    validAcc.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[1,0] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[0,1]))                              \n",
    "    print 'Test = ', balance_classification_rate\n",
    "    testAcc.append(balance_classification_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TrainNumber = [500, 1000, 5000, 10000, 15000, 17000]\n",
    "\n",
    "#sns.plt.plot(TrainNumber, trainAcc, label='Train');\n",
    "sns.plt.plot(TrainNumber, testAcc, label='Test');\n",
    "sns.plt.plot(TrainNumber, validAcc, label='Valid');\n",
    "sns.plt.ylim([0.66,0.75])\n",
    "sns.plt.xlabel(\"Number of sample\")\n",
    "sns.plt.title('Accuracy over sample number')\n",
    "sns.plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "trainAcc = []\n",
    "validAcc = []\n",
    "testAcc = []\n",
    "\n",
    "for i in [50, 100, 500, 1000, 1500, 2000, 3000, 4000, 4096]:\n",
    "\n",
    "    SelectKBestFeature = SelectKBest(chi2, k=i).fit(trainX, trainY[0])\n",
    "    trainXFeature = SelectKBestFeature.transform(trainX)\n",
    "    validXFeature = SelectKBestFeature.transform(validX)\n",
    "    testXFeature = SelectKBestFeature.transform(testX)\n",
    "    \n",
    "    trainXT = trainXFeature\n",
    "    validXT = validXFeature\n",
    "    testXT = testXFeature\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(trainXT, trainY[0])\n",
    "\n",
    "    trainPreY = clf.predict(trainXT)\n",
    "    validPreY = clf.predict(validXT)\n",
    "    testPreY = clf.predict(testXT)\n",
    "\n",
    "    confusion_matrix1 = confusion_matrix(trainY[0], trainPreY)\n",
    "    confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "    confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[0,1] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[1,0]))                              \n",
    "    print 'Train = ', balance_classification_rate\n",
    "    trainAcc.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[0,1] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[1,0]))                              \n",
    "    print 'Valid = ', balance_classification_rate\n",
    "    validAcc.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[0,1] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[1,0]))                              \n",
    "    print 'Test = ', balance_classification_rate\n",
    "    testAcc.append(balance_classification_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FeatureNumber = [50, 100, 500, 1000, 1500, 2000, 3000, 4000, 4096]\n",
    "\n",
    "#sns.plt.plot(FeatureNumber, trainAcc, label='Train');\n",
    "sns.plt.plot(FeatureNumber, testAcc, label='Test');\n",
    "sns.plt.plot(FeatureNumber, validAcc, label='Valid');\n",
    "sns.plt.ylim([0.70,0.75])\n",
    "sns.plt.xlabel(\"Number of feature\")\n",
    "sns.plt.title('Accuracy over feature number')\n",
    "sns.plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "trainXScale = min_max_scaler.fit_transform(trainX)\n",
    "validXScale = min_max_scaler.fit_transform(validX)\n",
    "testXScale = min_max_scaler.fit_transform(testX)\n",
    "\n",
    "\n",
    "SelectKBestFeature = SelectKBest(chi2, k=50).fit(trainXScale, trainY[0])\n",
    "trainXFeature = SelectKBestFeature.transform(trainXScale)\n",
    "validXFeature = SelectKBestFeature.transform(validXScale)\n",
    "testXFeature = SelectKBestFeature.transform(testXScale)\n",
    "\n",
    "trainXT = trainXFeature\n",
    "validXT = validXFeature\n",
    "testXT = testXFeature\n",
    "\n",
    "\n",
    "trainAcc1 = []\n",
    "validAcc1 = []\n",
    "testAcc1 = []\n",
    "\n",
    "for i in [1, 0.5, 0.1, 0.05, 0.01]:\n",
    "\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=i,max_depth=1, random_state=0)\n",
    "    clf = clf.fit(trainXT, trainY[0])\n",
    "\n",
    "    trainPreY = clf.predict(trainXT)\n",
    "    validPreY = clf.predict(validXT)\n",
    "    testPreY = clf.predict(testXT)\n",
    "\n",
    "    confusion_matrix1 = confusion_matrix(trainY[0], trainPreY)\n",
    "    confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "    confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[0,1] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[1,0]))                              \n",
    "    print 'Train = ', balance_classification_rate\n",
    "    trainAcc1.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[0,1] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[1,0]))                              \n",
    "    print 'Valid = ', balance_classification_rate\n",
    "    validAcc1.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[0,1] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[1,0]))                              \n",
    "    print 'Test = ', balance_classification_rate\n",
    "    testAcc1.append(balance_classification_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LearningRate = [1, 0.5, 0.1, 0.05, 0.01]\n",
    "\n",
    "sns.plt.plot(LearningRate, trainAcc1, label='Train');\n",
    "sns.plt.plot(LearningRate, testAcc1, label='Test');\n",
    "sns.plt.plot(LearningRate, validAcc1, label='Valid');\n",
    "sns.plt.ylim([0.8,0.83])\n",
    "sns.plt.xlabel(\"Learning Rate (The number of boosting stages = 100)\")\n",
    "sns.plt.title('Accuracy of Gradient Boosting Classifier')\n",
    "sns.plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "trainXScale = min_max_scaler.fit_transform(trainX)\n",
    "validXScale = min_max_scaler.fit_transform(validX)\n",
    "testXScale = min_max_scaler.fit_transform(testX)\n",
    "\n",
    "\n",
    "SelectKBestFeature = SelectKBest(chi2, k=50).fit(trainXScale, trainY[0])\n",
    "trainXFeature = SelectKBestFeature.transform(trainXScale)\n",
    "validXFeature = SelectKBestFeature.transform(validXScale)\n",
    "testXFeature = SelectKBestFeature.transform(testXScale)\n",
    "\n",
    "trainXT = trainXFeature\n",
    "validXT = validXFeature\n",
    "testXT = testXFeature\n",
    "\n",
    "trainAcc2 = []\n",
    "validAcc2 = []\n",
    "testAcc2 = []\n",
    "\n",
    "for i in [100, 150, 200,250,300,500,600]:\n",
    "\n",
    "    clf = GradientBoostingClassifier(n_estimators=i, learning_rate=0.8,max_depth=1, random_state=0)\n",
    "    clf = clf.fit(trainXT, trainY[0])\n",
    "\n",
    "    trainPreY = clf.predict(trainXT)\n",
    "    validPreY = clf.predict(validXT)\n",
    "    testPreY = clf.predict(testXT)\n",
    "\n",
    "    confusion_matrix1 = confusion_matrix(trainY[0], trainPreY)\n",
    "    confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "    confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[0,1] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[1,0]))                              \n",
    "    print 'Train = ', balance_classification_rate\n",
    "    trainAcc2.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[0,1] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[1,0]))                              \n",
    "    print 'Valid = ', balance_classification_rate\n",
    "    validAcc2.append(balance_classification_rate)\n",
    "\n",
    "    balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[0,1] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[1,0]))                              \n",
    "    print 'Test = ', balance_classification_rate\n",
    "    testAcc2.append(balance_classification_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EstimatorNumber = [100, 150, 200,250,300,500,600]\n",
    "\n",
    "sns.plt.plot(EstimatorNumber, trainAcc2, label='Train');\n",
    "sns.plt.plot(EstimatorNumber, testAcc2, label='Test');\n",
    "sns.plt.plot(EstimatorNumber, validAcc2, label='Valid');\n",
    "\n",
    "sns.plt.xlabel(\"Number of boosting stages to perform (Learning Rate = 0.8)\")\n",
    "sns.plt.title('Accuracy of Gradient Boosting Classifier')\n",
    "sns.plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA,  IncrementalPCA\n",
    "\n",
    "ipca = IncrementalPCA(n_components=200, batch_size=200)\n",
    "X_train_ipca = ipca.fit_transform(trainX)\n",
    "X_test_ipca= ipca.fit_transform(testX)\n",
    "X_valid_ipca= ipca.fit_transform(validX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "SelectKBestFeature = SelectKBest(chi2, k=200).fit(trainX, trainY[0])\n",
    "trainXFeature = SelectKBestFeature.transform(trainX)\n",
    "validXFeature = SelectKBestFeature.transform(validX)\n",
    "testXFeature = SelectKBestFeature.transform(testX)\n",
    "\n",
    "trainXT = trainXFeature\n",
    "validXT = validXFeature\n",
    "testXT = testXFeature\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=600, learning_rate=0.8,max_depth=1, random_state=0)\n",
    "clf = clf.fit(trainXT, trainY[0])\n",
    "\n",
    "trainPreY = clf.predict(trainXT)\n",
    "validPreY = clf.predict(validXT)\n",
    "testPreY = clf.predict(testXT)\n",
    "\n",
    "confusion_matrix1 = confusion_matrix(trainY[0], trainPreY)\n",
    "confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[0,1] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[1,0]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[0,1] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[1,0]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[0,1] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[1,0]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1,max_depth=1, random_state=0)\n",
    "clf = clf.fit(X_train_ipca, trainY[0])\n",
    "\n",
    "trainPreY = clf.predict(X_train_ipca)\n",
    "validPreY = clf.predict(X_test_ipca)\n",
    "testPreY = clf.predict(X_valid_ipca)\n",
    "\n",
    "confusion_matrix1 = confusion_matrix(trainY[0], trainPreY)\n",
    "confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[0,1] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[1,0]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[0,1] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[1,0]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate\n",
    "\n",
    "balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[0,1] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[1,0]))                              \n",
    "print 'Balance Classification Rate = ', balance_classification_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_list = [ 0.816291854073,0.789367970005,0.796932839767, 0.822388805597,0.580878414569,0.59201480698]\n",
    "models = ['CNN','CNN','CNN',\n",
    "          'PCA','PCA','PCA']\n",
    "sets = ['train','test','valid','train','test','valid']\n",
    "\n",
    "raw_data = {'Scores': scores_list, 'Features': models, 'Sets': sets}\n",
    "\n",
    "print((scores_list))\n",
    "\n",
    "df = pd.DataFrame(raw_data, columns=['Scores', 'Features', 'Sets'])\n",
    "#df.pivot(index='Features', columns='Sets', values='Scores')\n",
    "\n",
    "\n",
    "ax = sns.barplot(x='Features', y='Scores', hue='Sets',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn import preprocessing\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "i=0\n",
    "\n",
    "trainAcc = []\n",
    "validAcc = []\n",
    "testAcc = []\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "trainXScale = min_max_scaler.fit_transform(trainX)\n",
    "validXScale = min_max_scaler.fit_transform(validX)\n",
    "testXScale = min_max_scaler.fit_transform(testX)\n",
    "\n",
    "\n",
    "SelectKBestFeature = SelectKBest(chi2, k=50).fit(trainXScale, trainY[0])\n",
    "trainXFeature = SelectKBestFeature.transform(trainXScale)\n",
    "validXFeature = SelectKBestFeature.transform(validXScale)\n",
    "testXFeature = SelectKBestFeature.transform(testXScale)\n",
    "\n",
    "trainXT = trainXFeature\n",
    "validXT = validXFeature\n",
    "testXT = testXFeature\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.8,max_depth=1, random_state=0)\n",
    "clf = clf.fit(trainXT, trainY[0])\n",
    "\n",
    "trainPreY = clf.predict(trainXT)\n",
    "validPreY = clf.predict(validXT)\n",
    "testPreY = clf.predict(testXT)\n",
    "\n",
    "confusion_matrix1 = confusion_matrix(trainY[0], trainPreY)\n",
    "confusion_matrix2 = confusion_matrix(validY[0], validPreY)\n",
    "confusion_matrix3 = confusion_matrix(testY[0], testPreY)\n",
    "    \n",
    "#balance_classification_rate = 1/2 * ( float(confusion_matrix1[1,1])/float(confusion_matrix1[0,1] + confusion_matrix1[1,1]) ) + ( float(confusion_matrix1[0,0])/float(confusion_matrix1[0,0] + confusion_matrix1[1,0]))                              \n",
    "print 'Train = ', confusion_matrix1\n",
    "#trainAcc.append(balance_classification_rate)\n",
    "\n",
    "#balance_classification_rate = 1/2 * ( float(confusion_matrix2[1,1])/float(confusion_matrix2[0,1] + confusion_matrix2[1,1]) ) + ( float(confusion_matrix2[0,0])/float(confusion_matrix2[0,0] + confusion_matrix2[1,0]))                              \n",
    "print 'Valid = ', confusion_matrix2\n",
    "#validAcc.append(balance_classification_rate)\n",
    "\n",
    "#balance_classification_rate = 1/2 * ( float(confusion_matrix3[1,1])/float(confusion_matrix3[0,1] + confusion_matrix3[1,1]) ) + ( float(confusion_matrix3[0,0])/float(confusion_matrix3[0,0] + confusion_matrix3[1,0]))                              \n",
    "print 'Test = ', confusion_matrix3\n",
    "#testAcc.append(balance_classification_rate)\n",
    "    \n",
    "\n",
    "fpr_train, tpr_train, _ = roc_curve(trainY[i], trainPreY)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "fpr_test, tpr_test, _ = roc_curve(testY[i], testPreY)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "fpr_valid, tpr_valid, _ = roc_curve(validY[i], validPreY)\n",
    "roc_auc_valid = auc(fpr_valid, tpr_valid)\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(testY.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "colors = ['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange']\n",
    "lw = 2\n",
    "plt.plot(fpr_train, tpr_train, lw=lw, color=colors[0],\n",
    "             label='ROC fold %d (area_train = %0.2f)' % (i, roc_auc_train))\n",
    "plt.plot(fpr_test, tpr_test, lw=lw, color=colors[1],\n",
    "             label='ROC fold %d (area_test = %0.2f)' % (i, roc_auc_test))\n",
    "plt.plot(fpr_valid, tpr_valid, lw=lw, color=colors[2],\n",
    "             label='ROC fold %d (area_valid = %0.2f)' % (i, roc_auc_valid))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',\n",
    "         label='Luck')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
